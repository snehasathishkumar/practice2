{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sent_tokenize, word_tokenize\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from compound_to_simple import compound_to_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    # Tokenize words and remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_sentences = [' '.join([word for word in word_tokenize(sentence.lower()) if word.isalnum() and word not in stop_words])\n",
    "                           for sentence in sentences]\n",
    "    return sentences, processed_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_cosine_similarity(sentences, processed_sentences):\n",
    "    # Create TF-IDF vectorizer and transform sentences\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(processed_sentences)\n",
    "    # Compute cosine similarity matrix\n",
    "    cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return cosine_sim_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extractive_summarization(text, top_n=3):\n",
    "    # Preprocess text\n",
    "    sentences, processed_sentences = preprocess_text(text)\n",
    "    # Compute cosine similarity matrix\n",
    "    cosine_sim_matrix = compute_cosine_similarity(sentences, processed_sentences)\n",
    "    # Rank sentences based on their average cosine similarity to other sentences\n",
    "    sentence_scores = np.sum(cosine_sim_matrix, axis=1)\n",
    "    # Get top N sentences\n",
    "    top_sentence_indices = np.argsort(sentence_scores)[-top_n:]\n",
    "    top_sentences = [sentences[index] for index in sorted(top_sentence_indices)]\n",
    "    # Combine top sentences to form the summary\n",
    "    summary = ' '.join(top_sentences)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "## Cybersecurity Simplified: Understanding the 2024 Data Breach Investigations Report\n",
      "\n",
      "**Welcome to Verizon's 2024 Data Breach Investigations Report (DBIR). ** This report is about cybercrime and its impact on organizations. It's in its 17th year and analyzes real-world security incidents from around the globe. ** These include zero-day vulnerabilities like the one that affected MOVEit, ransomware, and denial-of-service attacks. Cybercriminals continue to find ways to exploit vulnerabilities and steal data. **The report also emphasizes the human element in cybersecurity. **  Poorly protected passwords and human errors make organizations vulnerable to attacks. **The DBIR analyzed over 30,000 security incidents, with over 10,000 confirmed data breaches. **  \n",
      "\n",
      "**The report wouldn't be possible without the contributions of global security experts and organizations. ** If you'd like to learn more about citing the report, the information is available. ## Cybersecurity: Simple Takeaways from the Verizon 2024 Data Breach Investigations Report\n",
      "\n",
      "**Exploiting Vulnerabilities on the Rise:** Attacks that exploit vulnerabilities are rising significantly, almost tripling since last year (Verizon 2024 Data Breach Investigations Report). This is likely due to vulnerabilities like MOVEit and other zero-day exploits. These attacks are commonly used by ransomware and extortion actors. **Ransomware and Extortion Dominate:** Roughly one-third of all breaches involved ransomware or some other extortion technique (Verizon 2024 Data Breach Investigations Report). Pure extortion attacks have increased, now making up 9% of all breaches. While traditional ransomware attacks have declined slightly to 23%, the combination of ransomware and extortion attacks represents a strong growth to 32% of breaches. **Human Error Still a Major Factor:** The human element was a factor in 68% of breaches (Verizon 2024 Data Breach Investigations Report). **Third-Party Risks Increasing:**  The report now includes a broader definition of third-party breaches, including partner infrastructure and software supply chain issues. This category grew by 68% to 15% of all breaches, driven by zero-day exploits for ransomware and extortion attacks (Verizon 2024 Data Breach Investigations Report). **Errors More Common Than Thought:** The number of breaches involving errors has increased to 28% (Verizon 2024 Data Breach Investigations Report). **Financial Motivation Drives Attackers:** Threat actors primarily use attack techniques that offer the highest return on investment (Verizon 2024 Data Breach Investigations Report). **Ransomware and Extortion Remain Dominant:**  Over the last three years, ransomware and extortion attacks consistently accounted for almost two-thirds (between 59% and 66%) of all breaches (Verizon 2024 Data Breach Investigations Report). Here are the simplified sentences from the provided text:\n",
      "\n",
      "* The average loss from ransomware and extortion attacks is $46,000. * Pretexting attacks, often involving Business Email Compromise (BEC), make up about 25% of financially motivated attacks. * The average amount stolen in BEC attacks is around $50,000. * Phishing attacks are becoming more common. * In 2023, 20% of users reported phishing attacks in simulations. * 11% of those who clicked on a phishing email reported it. * People take an average of 21 seconds to click on a malicious link after opening a phishing email. * They then take another 28 seconds to enter their data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "text = compound_to_simple()\n",
    "\n",
    "summary = extractive_summarization(text, top_n=30)\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"summary_stc\",\"w\") as f:\n",
    "    f.write(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
