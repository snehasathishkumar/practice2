{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\99013031\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\99013031\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\Users\\99013031\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from compound_to_simple import compound_to_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    # Tokenize words and remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_sentences = [' '.join([word for word in word_tokenize(sentence.lower()) if word.isalnum() and word not in stop_words])\n",
    "                           for sentence in sentences]\n",
    "    return sentences, processed_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_cosine_similarity(sentences, processed_sentences):\n",
    "    # Create TF-IDF vectorizer and transform sentences\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(processed_sentences)\n",
    "    # Compute cosine similarity matrix\n",
    "    cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    return cosine_sim_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extractive_summarization(text, top_n=3):\n",
    "    # Preprocess text\n",
    "    sentences, processed_sentences = preprocess_text(text)\n",
    "    # Compute cosine similarity matrix\n",
    "    cosine_sim_matrix = compute_cosine_similarity(sentences, processed_sentences)\n",
    "    # Rank sentences based on their average cosine similarity to other sentences\n",
    "    sentence_scores = np.sum(cosine_sim_matrix, axis=1)\n",
    "    # Get top N sentences\n",
    "    top_sentence_indices = np.argsort(sentence_scores)[-top_n:]\n",
    "    top_sentences = [sentences[index] for index in sorted(top_sentence_indices)]\n",
    "    # Combine top sentences to form the summary\n",
    "    summary = ' '.join(top_sentences)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Welcome to Verizon's 2024 Data Breach Investigations Report (DBIR). This is the 17th edition of the report. Data and insights from contributors around the world help us analyze cybercrime trends globally. We see new and innovative attacks as well as variations of older, successful attacks. Criminals continue to exploit vulnerabilities, such as the one that affected MOVEit, and use ransomware and denial-of-service (DoS) attacks. Cybercrime has been very active in the past year. We analyzed 30,458 security incidents, of which 10,626 were data breaches. The structure of the report remains similar, but there are some changes. We encourage new readers to review Appendix A before diving into the report. The 2024 DBIR dataset includes incidents from November 1, 2022, through October 31, 2023. The report focuses primarily on the 2023 data. The time between the data collection and report publication is spent acquiring, anonymizing, aggregating, analyzing, and writing the report. People like to cite the report and ask how to do so properly. Attacks involving the exploitation of vulnerabilities have increased significantly. This increase is due to vulnerabilities like MOVEit and similar zero-day vulnerabilities. These attacks are primarily used by Ransomware and Extortion threat actors. Ransomware and other Extortion techniques were involved in about one-third of all breaches. Pure Extortion attacks are now a component of 9% of all breaches. Ransomware was a top threat across 92% of industries. The human element was a component of 68% of breaches. Breaches involving a third party increased to 15%, a 68% increase from the previous year. This is mostly due to the use of zero-day exploits for Ransomware and Extortion attacks. Breaches involving Errors increased to 28% as the contributor base broadened. Financially motivated threat actors typically stick to attack techniques that give them the most return on investment. The combination of Ransomware and other Extortion breaches accounted for almost two-thirds of those attacks over the past three years. (Source: Verizon 2024 Data Breach Investigations Report) \n",
      "The median loss from ransomware and extortion breaches is $46,000. Pretexting attacks, often involving Business Email Compromise, account for 24% to 25% of financially motivated attacks. The median transaction amount for BEC is around $50,000. The median time to click on a malicious link after opening the email is 21 seconds. The median time for users to fall for phishing emails is less than 60 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "text = compound_to_simple()\n",
    "\n",
    "summary = extractive_summarization(text, top_n=30)\n",
    "print(\"Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"summary.txt\",\"w\") as f:\n",
    "    f.write(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
