{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down the `system_instruction` parameter within the Google Generative AI `GenerativeModel` class.\n",
      "\n",
      "**What is a System Instruction?**\n",
      "\n",
      "A system instruction is a way to provide **contextual guidance** to the AI model before it starts generating text. It's like giving the model a set of **pre-defined rules or persona** to follow during its response generation.\n",
      "\n",
      "**Why Use System Instructions?**\n",
      "\n",
      "* **Control Tone and Style:** You can specify the desired tone (formal, informal, humorous, etc.) and writing style (e.g., bullet points, narrative, technical).\n",
      "* **Define Persona:**  You can instruct the model to act as a specific persona, like a customer service representative, a technical expert, or a creative writer.\n",
      "* **Set Boundaries:** You can define limits on the model's responses, such as avoiding certain topics or adhering to specific guidelines.\n",
      "\n",
      "**Example with `google.generativeai.GenerativeModel`**\n",
      "\n",
      "```python\n",
      "from google.generativeai import (\n",
      "    GenerativeModel,\n",
      "    content_types,\n",
      "    generation_types,\n",
      "    safety_types,\n",
      ")\n",
      "\n",
      "# Define a system instruction\n",
      "system_instruction = content_types.ContentType(\n",
      "    content=\"You are a helpful and polite customer service agent. \"\n",
      "    \"Respond to user queries in a friendly and informative manner.\"\n",
      ")\n",
      "\n",
      "# Create a GenerativeModel instance\n",
      "model = GenerativeModel(\n",
      "    model_name=\"gemini-pro\",\n",
      "    system_instruction=system_instruction,\n",
      ")\n",
      "\n",
      "# Generate a response\n",
      "response = model.generate_text(\n",
      "    \"What is the return policy for this product?\"\n",
      ")\n",
      "\n",
      "print(response.content)\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1. **Import Necessary Modules:** We import the required modules from the `google.generativeai` library.\n",
      "2. **Define System Instruction:** We create a `ContentType` object to hold our system instruction. In this case, we tell the model to act as a friendly customer service agent.\n",
      "3. **Create GenerativeModel:** We instantiate a `GenerativeModel` object, specifying the model name (`gemini-pro`) and our system instruction.\n",
      "4. **Generate Text:** We use the `generate_text` method to get a response to the user query.\n",
      "5. **Print Response:** The model's response, adhering to the system instruction, is printed.\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* **Flexibility:** System instructions are a powerful tool for customizing the behavior of your AI model.\n",
      "* **Clarity:**  Clearly define your desired persona, tone, and boundaries within the system instruction.\n",
      "* **Experimentation:**  Try different system instructions to see how they affect the model's responses.\n",
      "\n",
      "Let me know if you'd like to explore more specific examples or have any other questions! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import dotenv\n",
    "\n",
    "api_key = dotenv.get_key(\".env\" , key_to_get=\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "gen_config = genai.GenerationConfig(temperature=0.1)\n",
    "model = genai.GenerativeModel( \"models/gemini-1.5-flash\" , generation_config=gen_config )\n",
    "reponse = model.generate_content(\"\"\"Explain system instruction with an example google.generativeai.GenerativeModel(\n",
    "    model_name: str = 'gemini-pro',\n",
    "    safety_settings: (safety_types.SafetySettingOptions | None) = None,\n",
    "    generation_config: (generation_types.GenerationConfigType | None) = None,\n",
    "    tools: (content_types.FunctionLibraryType | None) = None,\n",
    "    tool_config: (content_types.ToolConfigType | None) = None,\n",
    "    system_instruction: (content_types.ContentType | None) = None\n",
    ")\n",
    "                                 \"\"\")\n",
    "print(reponse.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
